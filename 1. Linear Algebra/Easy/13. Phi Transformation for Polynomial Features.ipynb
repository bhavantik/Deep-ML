{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Phi Transformation for Polynomial Features\n",
    "- Deep-ML: https://www.deep-ml.com/problems/84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "- Write a Python function to perform a Phi Transformation that maps input features into a higher-dimensional space by generating polynomial features. The transformation allows models like linear regression to fit nonlinear data by introducing new feature dimensions that represent polynomial combinations of the original input features. The function should take a list of numerical data and a degree as inputs, and return a nested list where each inner list represents the transformed features of a data point. If the degree is less than 0, the function should return an empty list.\n",
    "\n",
    "### ðŸ§® Example\n",
    "\n",
    "**Input:**\n",
    "```\n",
    "data = [1.0, 2.0], degree = 2\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "[[1.0, 1.0, 1.0], [1.0, 2.0, 4.0]]\n",
    "```\n",
    "\n",
    "**Reasoning:**\n",
    "- The Phi Transformation generates polynomial features for each data point up to the specified degree. For data = [1.0, 2.0] and degree = 2, the transformation creates a nested list where each row contains powers of the data point from 0 to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the about the topic\n",
    "Certainly! Below is the text formatted for Jupyter Notebook markdown, ensuring that all formulas are clearly visible using LaTeX:\n",
    "\n",
    "```markdown\n",
    "# Phi Transformation\n",
    "\n",
    "The Phi Transformation maps input features into a higher-dimensional space by generating polynomial features. This allows models like linear regression to fit nonlinear data by introducing new feature dimensions that represent polynomial combinations of the original input features.\n",
    "\n",
    "## Why Use Phi Transformation?\n",
    "\n",
    "- To increase the expressive power of simple models such as linear models.\n",
    "- To enable better fitting of nonlinear relationships in the data.\n",
    "\n",
    "## Equations\n",
    "\n",
    "For an input value \\(x\\), the Phi Transformation expands it as:\n",
    "\n",
    "\\[\n",
    "\\Phi(x) = [1, x, x^2, x^3, \\ldots, x^d]\n",
    "\\]\n",
    "\n",
    "Where \\(d\\) is the specified degree, and \\(\\Phi(x)\\) represents the transformed feature vector.\n",
    "\n",
    "## Example 1: Polynomial Expansion for One Value\n",
    "\n",
    "Given \\(x = 3\\) and \\(d = 3\\), the Phi Transformation is:\n",
    "\n",
    "\\[\n",
    "\\Phi(3) = [1, 3, 9, 27]\n",
    "\\]\n",
    "\n",
    "## Example 2: Transformation for Multiple Values\n",
    "\n",
    "For \\(\\text{data} = [1, 2]\\) and \\(d = 2\\), the Phi Transformation is:\n",
    "\n",
    "\\[\n",
    "\\Phi([1, 2]) = \\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "1 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "```\n",
    "\n",
    "This format uses LaTeX syntax for mathematical formulas, ensuring that all mathematical expressions are clearly visible and well-formatted in Jupyter Notebook markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 3.0, 9.0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def phi_transform(data: list[float], degree: int) -> list[list[float]]:\n",
    "\t\"\"\"\n",
    "\tPerform a Phi Transformation to map input features into a higher-dimensional space by generating polynomial features.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdata (list[float]): A list of numerical values to transform.\n",
    "\t\tdegree (int): The degree of the polynomial expansion.\n",
    "\n",
    "\t\"\"\"\n",
    "\t# Your code here\n",
    "\tphi_transform_mat = []\n",
    "\tfor i in data:\n",
    "\t\tans = [1.0]\n",
    "\t\tfor deg in range(degree):\n",
    "\t\t\tans.append(ans[-1]*i)\n",
    "\t\tphi_transform_mat.append(ans)\n",
    "\treturn phi_transform_mat\n",
    "\n",
    "data = [3]\n",
    "degree = 2\n",
    "\n",
    "print(phi_transform(data, degree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi Transformation for x=3 and degree=3: [[ 1.  3.  9. 27.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def phi_transformation(data, degree):\n",
    "    \"\"\"\n",
    "    Perform the Phi Transformation on input data, generating polynomial features.\n",
    "\n",
    "    Parameters:\n",
    "    data: np.ndarray or list\n",
    "        Input data (single value or list of values).\n",
    "    degree: int\n",
    "        The degree of the polynomial features.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray\n",
    "        Transformed data with polynomial features.\n",
    "    \"\"\"\n",
    "    # Ensure input data is a numpy array\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # Initialize the transformed data array\n",
    "    transformed_data = np.ones((len(data), degree + 1))\n",
    "    \n",
    "    # Generate polynomial features\n",
    "    for i in range(1, degree + 1):\n",
    "        transformed_data[:, i] = data ** i\n",
    "    \n",
    "    return transformed_data\n",
    "\n",
    "# Example usage for one value\n",
    "x = 3\n",
    "degree = 3\n",
    "phi_x = phi_transformation([x], degree)\n",
    "print(f\"Phi Transformation for x={x} and degree={degree}: {phi_x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QnA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Phi Transformation, often referred to as polynomial feature expansion, has several real-world applications across various domains. Here are some notable use cases:\n",
    "\n",
    "1. **Machine Learning and Data Science**:\n",
    "   - **Linear Regression**: By transforming features into a higher-dimensional polynomial space, linear regression models can capture nonlinear relationships in data, making them more flexible and expressive.\n",
    "   - **Support Vector Machines (SVMs)**: Polynomial feature expansion is used with kernel methods to separate data that is not linearly separable in its original feature space.\n",
    "   - **Neural Networks**: Although neural networks inherently capture nonlinearities, preprocessing data with polynomial features can sometimes lead to better performance for certain architectures and datasets.\n",
    "\n",
    "2. **Finance**:\n",
    "   - **Option Pricing**: Polynomial expansions can be used to model complex financial instruments and derivatives where nonlinear relationships exist between variables.\n",
    "   - **Risk Management**: Polynomial regression can model nonlinear risk factors, helping in assessing potential financial risks more accurately.\n",
    "\n",
    "3. **Engineering**:\n",
    "   - **Signal Processing**: Polynomial transformations can be used for feature extraction and enhancement in signals, aiding in noise reduction and improving signal clarity.\n",
    "   - **Control Systems**: Polynomial models are utilized in designing control systems that need to account for nonlinear dynamics in mechanical systems.\n",
    "\n",
    "4. **Healthcare**:\n",
    "   - **Medical Diagnostics**: Polynomial feature transformation can improve the accuracy of predictive models for diagnosing diseases by capturing nonlinear relationships between symptoms and outcomes.\n",
    "   - **Genomic Data Analysis**: In bioinformatics, polynomial transformations can help model complex interactions in genetic data, aiding in understanding genetic predispositions to diseases.\n",
    "\n",
    "5. **Environmental Science**:\n",
    "   - **Climate Modeling**: Polynomial expansions can be used to model complex interactions between various environmental factors, leading to better predictions of climate change impacts.\n",
    "   - **Pollution Forecasting**: Polynomial features can help in understanding and predicting pollution levels by capturing nonlinear relationships between different pollutants and environmental conditions.\n",
    "\n",
    "6. **Marketing and Customer Analytics**:\n",
    "   - **Customer Behavior Modeling**: Polynomial transformations can improve models that predict customer purchasing behavior by capturing complex relationships between various demographic and behavioral factors.\n",
    "   - **Market Basket Analysis**: Enhancing models with polynomial features can help in understanding and predicting product affinities and cross-selling opportunities.\n",
    "\n",
    "These use cases illustrate the versatility of the Phi Transformation in enhancing model capabilities across diverse fields by capturing complex, nonlinear relationships that are often present in real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
